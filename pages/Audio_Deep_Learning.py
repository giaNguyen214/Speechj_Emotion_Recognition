import streamlit as st


st.set_page_config(page_title="Audio deep learning")
 


language = st.selectbox(
    "Select Language",
    ("English", "Vietnamese")
)

st.sidebar.title("üìö Table of Contents")
st.sidebar.markdown("""
- [Some important hyperparameters](#hyperparam)
- [Basic knowledge when doing with audio](#knowledge)
- [Spectrum (Fourier transform)](#spectrum)
- [Spectrogram](#spectrogram)
- [Mel filterbank](#filterbank)
""", unsafe_allow_html=True)


if language == "Vietnamese":
    st.image("images/audio_dl.jpg")
    st.write("Trong project n√†y, tr√≠ch xu·∫•t Mel spectrogram t·ª´ audio g·ªëc, ƒë∆∞a v√†o Convformer ƒë·ªÉ l·∫•y feature map v√† d√πng XGBoost ƒë·ªÉ ph√¢n lo·∫°i sau c√πng")

    st.markdown('<a id="hyperparam"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">M·ªôt s·ªë hyperparameters khi chuy·ªÉn ƒë·ªïi audio sang Mel spectrogram:</h3>', unsafe_allow_html=True)
    st.markdown("""
        - **sr (sampling rate)**: s·ªë m·∫´u m·ªói gi√¢y  
        - **n_fft**: s·ªë l∆∞·ª£ng ƒëi·ªÉm d√πng trong Fast Fourier Transform  
        - **hop_length**: kho·∫£ng th·ªùi gian tr∆∞·ª£t gi·ªØa c√°c ƒëo·∫°n  
        - **n_mel**: s·ªë l∆∞·ª£ng Mel bands  
        - **fmin**: t·∫ßn s·ªë th·∫•p nh·∫•t  
        - **fmax**: t·∫ßn s·ªë cao nh·∫•t  
        """)


    st.markdown('<a id="knowledge"></a>', unsafe_allow_html=True)
    st.write('<h3 style="color:#1E90FF;">M·ªôt s·ªë kh√°i ni·ªám c∆° b·∫£n</h3>', unsafe_allow_html=True)
    st.write("- **Dao ƒë·ªông**: m·ªôt dao ƒë·ªông l√† m·ªôt l·∫ßn di chuy·ªÉn t·ª´ v·ªã tr√≠ c√¢n b·∫±ng r·ªìi quay tr·ªü l·∫°i v·ªã tr√≠ c√¢n b·∫±ng. T∆∞∆°ng ƒë∆∞∆°ng m·ªôt l·∫ßn l·∫∑p l·∫°i c·ªßa s√≥ng.")
    st.write("- **Bi√™n ƒë·ªô (Amplitude)**: m·ª©c ƒë·ªô dao ƒë·ªông (r·ªông hay h·∫πp) c·ªßa s√≥ng √¢m. Quy·∫øt ƒë·ªãnh √¢m to hay nh·ªè.")
    st.write("- **T·∫ßn s·ªë (Frequency)**: s·ªë l·∫ßn dao ƒë·ªông trong m·ªôt gi√¢y. Quy·∫øt ƒë·ªãnh √¢m cao hay th·∫•p.")
    st.write("- **√Çm thanh ƒë∆°n t·∫ßn s·ªë**: √¢m ch·ªâ c√≥ 1 t·∫ßn s·ªë duy nh·∫•t.  \
            V√≠ d·ª•: m·ªôt √¢m 25Hz k√©o d√†i 5 gi√¢y th√¨ lu√¥n lu√¥n l√† 25 dao ƒë·ªông m·ªói gi√¢y trong su·ªët 5 gi√¢y.")
    st.write("- **√Çm thanh t·ªï h·ª£p (non-single frequency sound)**: l√† s·ª± k·∫øt h·ª£p c·ªßa nhi·ªÅu √¢m thanh ƒë∆°n t·∫ßn s·ªë.  \
            V√≠ d·ª•: √¢m thanh d√†i 5 gi√¢y th√¨ c√≥ th·ªÉ 2s ƒë·∫ßu l√† 25Hz, 2s ti·∫øp theo l√† t·ªï h·ª£p 7Hz v√† 19Hz, ƒëo·∫°n sau l√† 13Hz.")
    st.write("- **√Çm thanh th·ª±c t·∫ø**: l√† s·ª± t·ªïng h·ª£p c·ªßa nhi·ªÅu √¢m ƒë∆°n t·∫ßn s·ªë.  \
            ƒê·ªÉ ph√¢n t√≠ch, ta d√πng Fourier Transform ƒë·ªÉ ph√¢n r√£ (decompose) th√†nh c√°c t·∫ßn s·ªë c·∫•u th√†nh n√™n n√≥.")
    st.write("- **Analog signal**: t√≠n hi·ªáu li√™n t·ª•c theo th·ªùi gian.")
    st.write("- **Digital signal**: t√≠n hi·ªáu r·ªùi r·∫°c, l·∫•y m·∫´u (sampling) t·ª´ analog signal.")
    st.image("images/analog_digital.jpg")

        

    st.markdown('<a id="spectrum"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Spectrum (Fourier Transform)</h3>', unsafe_allow_html=True)
    st.image("images/time_Freq_domain.jpg")
    st.write("- **Mi·ªÅn th·ªùi gian**: tr·ª•c x l√† th·ªùi gian, tr·ª•c y l√† bi√™n ƒë·ªô.")
    st.write("- **Mi·ªÅn t·∫ßn s·ªë**: tr·ª•c x l√† t·∫ßn s·ªë, tr·ª•c y l√† bi√™n ƒë·ªô (m·ª©c ƒë·ªô xu·∫•t hi·ªán t·∫ßn s·ªë ƒë√≥).")
    st.write("- **Fourier Transform**: gi√∫p chuy·ªÉn ƒë·ªïi t√≠n hi·ªáu t·ª´ mi·ªÅn th·ªùi gian sang mi·ªÅn t·∫ßn s·ªë.  \
            V√≠ d·ª•: trong m·ªôt b·∫£n h√≤a nh·∫°c g·ªìm nhi·ªÅu √¢m thanh kh√°c nhau c√πng vang l√™n, con ng∆∞·ªùi v·∫´n ph√¢n bi·ªát ƒë∆∞·ª£c gi·ªçng ca sƒ©, ti·∫øng guitar, ti·∫øng piano,...")
    # st.latex(r'''
    #         X(f) = \int_{-\infty}^{\infty} x(t) \cdot e^{-j 2\pi f t} \, dt
    #     ''')
    # st.write("M√°y t√≠nh kh√¥ng th·ªÉ x·ª≠ l√Ω t√≠n hi·ªáu li√™n t·ª•c (analog signal) n√™n c·∫ßn chuy·ªÉn th√†nh t√≠n hi·ªáu r·ªùi r·∫°c (digital signal): [0.1, 0.5, 0.9, 0.7, 0.0, -0.6, -0.9, ...]\
    #         M·ªói gi√° tr·ªã l√† bi√™n ƒë·ªô t·∫°i m·ªôt th·ªùi ƒëi·ªÉm. M√°y t√≠nh c≈©ng kh√¥ng th·ªÉ t√≠nh t√≠ch ph√¢n v√¥ h·∫°n, n√™n d√πng c√¥ng th·ª©c Discrete fourier transform:")
    # st.latex(r'''
    #         X[k] = \sum_{n=0}^{N-1} x[n] \cdot e^{-j 2\pi k n / N}
    #     ''')
    # st.markdown("T√≠nh theo DFT th√¨ r·∫•t ch·∫≠m $O(N^2)$ n√™n chuy·ªÉn qua Fast fourier transform $O(NlogN)$")
    st.write("K·∫øt qu·∫£ Fourier Transform l√† **spectrum**, li·ªát k√™ c√°c t·∫ßn s·ªë xu·∫•t hi·ªán trong √¢m thanh.  \
            Tuy nhi√™n **kh√¥ng cho bi·∫øt th·ªùi ƒëi·ªÉm** xu·∫•t hi·ªán c√°c t·∫ßn s·ªë ƒë√≥. VD m·ªôt √¢m thanh c√≥ 2 gi√¢y ƒë·∫ßu l√† t·ªï h·ª£p c·ªßa 2 v√† 3Hz, 3 gi√¢y sau l√† t·ªï h·ª£p c·ªßa 17 v√† 23Hz.\
                Nh∆∞ng fourier transform ch·ªâ cho ta bi·∫øt √¢m thanh ƒë∆∞·ª£c t·ªï h·ª£p t·ª´ 2, 3, 17, 23 (Hz) m√† kh√¥ng bi·∫øt th·ªùi gian xu·∫•t hi·ªán")



    st.markdown('<a id="spectrogram"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Spectrogram</h3>', unsafe_allow_html=True)
    st.markdown(""" 
            **Short-Time Fourier Transform (STFT)** gi·∫£i quy·∫øt vi·ªác m·∫•t th√¥ng tin th·ªùi gian b·∫±ng c√°ch: 
            
            - Chia t√≠n hi·ªáu audio th√†nh c√°c ƒëo·∫°n nh·ªè  
            - √Åp d·ª•ng Fourier Transform l√™n t·ª´ng ƒëo·∫°n -> ra ƒë∆∞·ª£c spectrum 
            - Gh√©p c√°c k·∫øt qu·∫£ (spectrum) l·∫°i theo tr·ª•c th·ªùi gian 
        """)
    st.write("Sau khi t√≠nh ra, k·∫øt qu·∫£ c√≥ d·∫°ng (Time, Frequency, Amplitude) v·ªõi 2 tr·ª•c th·ªùi gian v√† t·∫ßn s·ªë, c√≤n bi√™n ƒë·ªô ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng m√†u s·∫Øc c·ªßa b·ª©c h√¨nh\
            V√† ta ti·∫øp t·ª•c l·∫•y log_scale = log(frequency) v√† decibel = log(amplitude) => k·∫øt qu·∫£ s·∫Ω c√≥ ƒë∆∞·ª£c spectrogram")


    st.markdown('<a id="filterbank"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Mel Filter Bank v√† Mel Scale</h3>', unsafe_allow_html=True)
    st.markdown("""
            - Kh·∫£ nƒÉng ph√¢n bi·ªát t·∫ßn s·ªë c·ªßa con ng∆∞·ªùi **kh√¥ng tuy·∫øn t√≠nh**.  
            V√≠ d·ª•:  
                - 100Hz vs 200Hz: ch√∫ng ta c√≥ th·ªÉ nh·∫≠n ra s·ª± kh√°c nhau c·ªßa 2 √¢m thanh -> d·ªÖ ph√¢n bi·ªát  
                - 4000Hz vs 4100Hz: h·∫ßu nh∆∞ kh√¥ng c·∫£m nh·∫≠n ƒë∆∞·ª£c s·ª± kh√°c bi·ªát -> kh√≥ ph√¢n bi·ªát m·∫∑c d√π c≈©ng c√°ch nhau 100Hz

            - V√¨ v·∫≠y, ng∆∞·ªùi ta d√πng mel filter bank, m·ª•c ƒë√≠ch l√† gi·∫£m s·ªë chi·ªÅu c·ªßa tr·ª•c t·∫ßn s·ªë v√† chuy·ªÉn v·ªÅ thang **Mel Scale** - m·ªôt thang t·∫ßn s·ªë phi tuy·∫øn t√≠nh ƒë·ªÉ m√¥ ph·ªèng c√°ch tai ng∆∞·ªùi c·∫£m nh·∫≠n √¢m thanh.
        """)
    st.markdown("""
            - n_mel: S·ªë l∆∞·ª£ng b·ªô l·ªçc chia tr√™n tr·ª•c t·∫ßn s·ªë ·ªü thang Mel. C≈©ng ch√≠nh l√† s·ªë chi·ªÅu c·ªßa tr·ª•c t·∫ßn s·ªë sau khi th·ª±c hi·ªán. \
                VD: ƒë·∫ßu v√†o l√† spectrogram (Time=5, Frequency=10000) c√≥ 5 frames th·ªùi gian, m·ªói frame c√≥ 10000 gi√° tr·ªã t·∫ßn s·ªë. Th√¨ ƒë·∫ßu ra s·∫Ω l√† (Time=5, Frequency=n_mel)
            - fmin: l√† ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·ªßa mel filter bank. N·∫øu l·∫•y cao th√¨ s·∫Ω b·ªè qua m·ªôt s·ªë √¢m, l·∫•y th·∫•p th√¨ n·∫Øm b·∫Øt ƒë∆∞·ª£c c√°c √¢m tr·∫ßm
            - fmax: l√† ƒëi·ªÉm k·∫øt th√∫c c·ªßa mel filter bank. N·∫øu l·∫•y cao th√¨ n·∫Øm b·∫Øt ƒë∆∞·ª£c c√°c √¢m cao, l·∫•y th·∫•p th√¨ b·ªè qua m·ªôt s·ªë √¢m
                    """)
        
            
    st.success("=> K·∫øt qu·∫£ cu·ªëi c√πng ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ·∫£nh v√† x·ª≠ l√Ω nh∆∞ m·ªôt b√†i to√°n image classfication b√¨nh th∆∞·ªùng")
    st.image("images/mel_spectrogram.jpg", caption="Mel spectrogram as a image for downsampling task (RAVDESS)")
    st.image("images/mel_spectrogram_ravdess.jpg", caption="Mel spectrogram as a image for downsampling task (CREMA-D)")
    
else:
    st.image("images/audio_dl.jpg", caption="General pipeline when handling audio input")
    st.markdown('<a id="hyperparam"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Some important hyperparameters when converting audio to Mel spectrogram:</h3>', unsafe_allow_html=True)
    st.markdown("""
        - **sr (sampling rate)**: number of samples per second  
        - **n_fft**: number of points used in the Fast Fourier Transform  
        - **hop_length**: stride (sliding step) between segments  
        - **n_mel**: number of Mel bands  
        - **fmin**: minimum frequency  
        - **fmax**: maximum frequency  
        """)

    st.markdown('<a id="knowledge"></a>', unsafe_allow_html=True)
    st.write('<h3 style="color:#1E90FF;">Some basic concepts</h3>', unsafe_allow_html=True)
    st.write("- **Vibration**: a repeated back-and-forth movement around a central point. It represents one full wave cycle.")
    st.write("- **Amplitude**: how strong or big the vibration is. Larger amplitude means the sound is louder, and smaller amplitude means it's quieter.")
    st.write("- **Frequency**: number of vibrations per second. Determines the pitch (high or low) of the sound.")
    st.write("- **Single-frequency sound**: sound that contains only one frequency.  \
            Example: a 25Hz tone lasting 5 seconds will always vibrate at 25 times per second.")
    st.write("- **Non-single frequency sound**: a combination of multiple single-frequency sounds.  \
            Example: a 5-second sound could consist of 25Hz in the first 2 seconds, a mix of 7Hz and 19Hz in the next 2 seconds, and 13Hz at the end.")
    st.write("- **Real-world sound**: a mixture of many single-frequency sounds.  \
            To analyze it, we use Fourier Transform to decompose it into its frequency components.")
    st.write("- **Analog signal**: a continuous signal over time.")
    st.write("- **Digital signal**: a discrete signal obtained by sampling from the analog signal.")
    st.image("images/analog_digital.jpg", caption="The curve represents the analog signal, while the individual points illustrate the sampling process used to convert it into a digital signal.")

    st.markdown('<a id="spectrum"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Spectrum (Fourier Transform)</h3>', unsafe_allow_html=True)
    st.image("images/time_Freq_domain.jpg")
    st.write("- **Time domain**: x-axis is time, y-axis is amplitude.")
    st.write("- **Frequency domain**: x-axis is frequency, y-axis is amplitude (indicating presence of frequency).")
    st.write("- **Fourier Transform**: converts a signal from time domain to frequency domain.  \
            For example: in a music performance with multiple instruments, humans can still distinguish the singer's voice, the guitar, the piano, etc.")
    # st.latex(r'''
    #         X(f) = \int_{-\infty}^{\infty} x(t) \cdot e^{-j 2\pi f t} \, dt
    #     ''')
    # st.write("Computers cannot process continuous signals (analog), so we convert them to digital signals: [0.1, 0.5, 0.9, 0.7, 0.0, -0.6, -0.9, ...] \
    #         where each value is the amplitude at a time step. Since computers also can‚Äôt calculate infinite integrals, we use Discrete Fourier Transform:")
    # st.latex(r'''
    #         X[k] = \sum_{n=0}^{N-1} x[n] \cdot e^{-j 2\pi k n / N}
    #     ''')
    # st.markdown("DFT is slow at $O(N^2)$ so we use Fast Fourier Transform with $O(NlogN)$ complexity.")
    st.write("The result of Fourier Transform is the **spectrum**, which lists the frequencies present in the sound.  \
            However, it does **not provide time information**. For example, a sound may consist of 2Hz and 3Hz in the first 2 seconds, then 17Hz and 23Hz in the next 3 seconds. \
                But the Fourier Transform only tells us the frequencies 2, 3, 17, 23 are present, not when.")

    st.markdown('<a id="spectrogram"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Spectrogram</h3>', unsafe_allow_html=True)
    st.markdown(""" 
            **Short-Time Fourier Transform (STFT)** solves the loss of time information by:  
            
            - Splitting the audio signal into small segments  
            - Applying Fourier Transform to each segment ‚Üí get spectrum  
            - Combining the results along the time axis  
        """)
    st.write("The result has the form (Time, Frequency, Amplitude). Time and frequency are axes, and amplitude is represented by the color of the image. \
            We then apply log scaling: log(frequency) and log(amplitude) ‚Üí the final result is a spectrogram.")

    st.markdown('<a id="filterbank"></a>', unsafe_allow_html=True)
    st.markdown('<h3 style="color:#1E90FF;">Mel Filter Bank and Mel Scale</h3>', unsafe_allow_html=True)
    st.markdown("""
            - Human frequency perception is **non-linear**.  
            For example:  
                - 100Hz vs 200Hz: we can clearly hear the difference  
                - 4000Hz vs 4100Hz: we can hardly tell the difference  

            - Therefore, huamn define something called a mel filter bank to reduce the frequency axis dimensions and convert to **Mel Scale** ‚Äì a non-linear frequency scale that mimics human auditory perception.
        """)
    st.markdown("""
            - n_mel: Number of filters on the Mel scale. This also becomes the new dimension of the frequency axis. \
                Example: original spectrogram has shape (Time=5, Frequency=10000), after applying filter bank ‚Üí (Time=5, Frequency=n_mel)
            - fmin: starting frequency of the mel filter bank. A higher fmin will skip some low-frequency sounds; a lower fmin will capture them.
            - fmax: ending frequency of the mel filter bank. A higher fmax captures high-frequency sounds; a lower fmax ignores them.
        """)

    st.success("=> The final result is visualized as an image and processed like a typical image classification task.")
    st.image("images/mel_spectrogram.jpg", caption="Mel spectrogram as an image for downsampling task (RAVDESS)")
    st.image("images/mel_spectrogram_ravdess.jpg", caption="Mel spectrogram as an image for downsampling task (CREMA-D)")
